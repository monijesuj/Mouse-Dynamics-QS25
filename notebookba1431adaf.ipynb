{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Mouse dynamics \n",
    "## User identification based on mouse activity fingerprint\n",
    "### Author: Nejm Jaafar - Data scientist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<h3> Introduction:</h3>\n",
    "\n",
    "\n",
    "In this notebook, we will analyze mouse event data with the aim to identify the user. <br>Mouse Dynamics is a behavioral biometrics technology used to validate a user’s identity by analyzing unique patterns - such as tiny hand motions - detected in the user’s interaction with their mouse or pointer. Mouse dynamics algorithms interpret the data gathered from a mouse or pointer to build a unique user profile. Mouse dynamics in authentication is essentially being able to validate someone’s identity by the way they use their mouse.<br>\n",
    "<h4> Datasets:</h4>\n",
    "\n",
    "• Train_Mouse.csv: In this dataset, the mouse events data from 20 users are collected.<br>\n",
    "The mouse events are collected during user interaction with a demo banking application. Each user is asked to do 6 sessions and for each session, the data of mouse events are collected. Each row of the dataset represents a single mouse event and consists of uid (unique identifier for each mouse event), session_id (session identifier), user_id, timestamp, event_type (mouse movement type), screen_x and screen_y (coordinates of the mouse event).<br>\n",
    "Every row of the mouse event data has an event_type column that shows what kind of mouse event the row represents. However, every row by itself does not represent the entire event, the event if oftentimes represented by multiple events in a row. <br>For example, a drag event is a event_type 4 (drag) followed by an indeterminate amount of event_type’s 2 (move) and ends with a event_type 1 (release).<br><br>\n",
    "The different event_type’s recorded are: \n",
    "- 1 = release\n",
    "- 2 = move \n",
    "- 3 = wheel \n",
    "- 4 = drag\n",
    "- 5 = click\n",
    "\n",
    "And the different events that can occur are:\n",
    "- click – one click event_type (5) followed by one release event_type (1)\n",
    "- move – indeterminate amount of move event_type’s (2)\n",
    "- drag – one drag event_type (4) followed by indeterminate amount of move event_type’s (2) ending with one release event_type (1) \n",
    "- wheel – indeterminate amount of wheel event_type’s (3)\n",
    "\n",
    "• Test_Mouse.csv: This dataset has the same structure as the Train dataset except that the user_id is not included.\n",
    "<h4> Objective:</h4>\n",
    "\n",
    "Determine UserID for each session_id in “Test_Mouse.csv” dataset based on collected mouse events data.\n",
    "\n",
    "<h4> Content:</h4>\n",
    "\n",
    "We will go through 4 major parts:\n",
    "- EDA that covers real simulation of the mouse, showing the exact path it took on the screen (space), plus temporal analysis for the user's session time. \n",
    "- Feature engineering part during which I derived insights from the X-Y-T and converted them into indicative features like slope, tightness, centers, frequencies, etc.\n",
    "- Model training, which shows the transformations of the dataset and running the multilayer perceptron classifier (Neural network).\n",
    "- Evaluation of the model using F1 score and confusion matrix, and introducing cross validation to reduce the over-fitting.\n",
    "- Generating the users IDs for the Test_mouse.csv file.\n",
    "- Conclusion and perspectives.\n",
    "\n",
    "We will use <b>Spark</b> for this implementation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:25:23.873418Z",
     "iopub.status.busy": "2023-04-16T13:25:23.87298Z",
     "iopub.status.idle": "2023-04-16T13:26:13.409087Z",
     "shell.execute_reply": "2023-04-16T13:26:13.407707Z",
     "shell.execute_reply.started": "2023-04-16T13:25:23.873378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA \u001b[38;5;28;01mas\u001b[39;00m skPCA\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA \u001b[38;5;28;01mas\u001b[39;00m spPCA\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Vectors\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossValidator, TrainValidationSplit, ParamGridBuilder, TrainValidationSplitModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sn\n",
    "import hashlib\n",
    "import binascii\n",
    "import math\n",
    "from sklearn.decomposition import PCA as skPCA\n",
    "from pyspark.ml.feature import PCA as spPCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import CrossValidator, TrainValidationSplit, ParamGridBuilder, TrainValidationSplitModel\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import StructType, StringType, FloatType, LongType, IntegerType, StructField\n",
    "from pyspark.sql import HiveContext, SparkSession\n",
    "from pyspark.sql.functions import countDistinct, array_distinct, col, isnan, when, count, lit, array\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:26:13.578287Z",
     "iopub.status.busy": "2023-04-16T13:26:13.577938Z",
     "iopub.status.idle": "2023-04-16T13:26:18.993823Z",
     "shell.execute_reply": "2023-04-16T13:26:18.992424Z",
     "shell.execute_reply.started": "2023-04-16T13:26:13.578254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize spark context\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:26:27.111731Z",
     "iopub.status.busy": "2023-04-16T13:26:27.110575Z",
     "iopub.status.idle": "2023-04-16T13:26:30.72893Z",
     "shell.execute_reply": "2023-04-16T13:26:30.727606Z",
     "shell.execute_reply.started": "2023-04-16T13:26:27.11168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "schemaMousePos = StructType([\n",
    "    StructField('uid', StringType(), False,),\n",
    "    StructField('session_id', StringType(), False),\n",
    "    StructField('user_id', StringType(), True),\n",
    "    StructField('timestamp', LongType(), False),\n",
    "    StructField('event_type', IntegerType(), False),\n",
    "    StructField('screen_x', FloatType(), False),\n",
    "    StructField('screen_y', FloatType(), False)\n",
    "])\n",
    "trainDs = spark.read.csv('/kaggle/input/mouse-dynamics-for-user-authentication/Train_Mouse.csv',header=True, schema=schemaMousePos)\n",
    "trainDs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:26:35.470973Z",
     "iopub.status.busy": "2023-04-16T13:26:35.470482Z",
     "iopub.status.idle": "2023-04-16T13:26:39.831574Z",
     "shell.execute_reply": "2023-04-16T13:26:39.830256Z",
     "shell.execute_reply.started": "2023-04-16T13:26:35.470926Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Make sure each session has only 1 user\n",
    "trainDs.groupBy('session_id').agg(countDistinct('user_id').alias('distinct_uids_per_session')).agg({'distinct_uids_per_session':'max'}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:26:39.833969Z",
     "iopub.status.busy": "2023-04-16T13:26:39.8335Z",
     "iopub.status.idle": "2023-04-16T13:26:40.620841Z",
     "shell.execute_reply": "2023-04-16T13:26:40.619516Z",
     "shell.execute_reply.started": "2023-04-16T13:26:39.83392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# let's check if the data is imbalanced\n",
    "trainDs.groupBy('user_id').agg(countDistinct('session_id')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:26:41.709989Z",
     "iopub.status.busy": "2023-04-16T13:26:41.709441Z",
     "iopub.status.idle": "2023-04-16T13:26:43.081626Z",
     "shell.execute_reply": "2023-04-16T13:26:43.080273Z",
     "shell.execute_reply.started": "2023-04-16T13:26:41.709928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# let's check for nones\n",
    "trainDs.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in trainDs.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### Ok perfect. The dataset looks balanced, free of missing values, and there is one user per session. Now let's draw some plots to help us understand the content of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### Here I will draw a color legend for the event transitions, which we'll use for the upcoming plots next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:26:49.158068Z",
     "iopub.status.busy": "2023-04-16T13:26:49.157651Z",
     "iopub.status.idle": "2023-04-16T13:26:49.594133Z",
     "shell.execute_reply": "2023-04-16T13:26:49.593174Z",
     "shell.execute_reply.started": "2023-04-16T13:26:49.158035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
    "eventMap = {1:'release', 2:'move', 3 : 'wheel', 4:'drag', 5 : 'click'}\n",
    "# set colormap\n",
    "colorsRevDict = {'#'+hashlib.md5((('{}-{}'.format(i, j))*16).encode()).hexdigest()[:6] : '{} -> {}'.format(eventMap[i],eventMap[j])  for i in range(1,6) for j in range(1,6)} \n",
    "soa = np.array([[0,i,1,j-i] for i in range(1,6) for j in range(1,6)])\n",
    "X, Y, U, V = zip(*soa)\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "# generate unique color for each transition, I'll simply use hash because I'm too lazy to create a linear distribution for colors\n",
    "colors = ['#'+hashlib.md5((('{}-{}'.format(i, j))*16).encode()).hexdigest()[:6] for i in range(1,6) for j in range(1,6)]\n",
    "ax.quiver(X, Y, U, V, angles='xy', scale_units='xy', scale=1, color=colors, linewidth=0.3)\n",
    "ax.set_xlim([-1,2])\n",
    "ax.set_ylim([0,6])\n",
    "plt.draw()\n",
    "plt.show()\n",
    "print(eventMap)\n",
    "print(colorsRevDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### Now let's see the users' screen movements in deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:26:55.352134Z",
     "iopub.status.busy": "2023-04-16T13:26:55.351733Z",
     "iopub.status.idle": "2023-04-16T13:28:30.744728Z",
     "shell.execute_reply": "2023-04-16T13:28:30.743364Z",
     "shell.execute_reply.started": "2023-04-16T13:26:55.3521Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [30, 15]\n",
    "df = trainDs.toPandas().sort_values('timestamp')\n",
    "# usersEncoder will simplify user_id strings into a small range values\n",
    "usersEncoder = {k:i for i,k in enumerate(trainDs.select('user_id').rdd.flatMap(lambda x: x).distinct().collect())}\n",
    "screenDims = ((df['screen_x'].min(),df['screen_x'].max()), (df['screen_y'].min(),df['screen_y'].max()))\n",
    "for userId in usersEncoder.keys(): # df['user_id'].unique():\n",
    "    portionDf = df[df['user_id']==userId]\n",
    "    print(usersEncoder[userId], userId)\n",
    "    for session in portionDf['session_id'].unique():\n",
    "        portionDfSession = portionDf[portionDf['session_id']==session]\n",
    "        XYs = np.array([(k[1].screen_x, k[1].screen_y) for k in portionDfSession.iterrows()]).astype(float) # xy\n",
    "        evs = [k[1].event_type for k in portionDfSession.iterrows()] # events\n",
    "        tss = [int(k[1].timestamp) for k in portionDfSession.iterrows()] # timestamps\n",
    "        soa = np.array([[XYs[i][0],XYs[i][1], XYs[i+1][0]-XYs[i][0],XYs[i+1][1]-XYs[i][1]] for i in range(len(XYs)-1)])\n",
    "        tsd = np.array([tss[i+1]-tss[i] for i in range(len(tss)-1)]).astype(int)\n",
    "        \n",
    "        X, Y, U, V = zip(*soa)\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "        colors = ['#'+hashlib.md5((('{}-{}'.format(evs[i], evs[i+1]))*16).encode()).hexdigest()[:6] for i in range(len(evs)-1)]\n",
    "        q = ax.quiver(X, Y, U, V, angles='xy', scale_units='xy', scale=1, color=colors, width=0.001) #, label=colors) \n",
    "        ax.set_xlim([screenDims[0][0]-100,screenDims[0][1]+100])\n",
    "        ax.set_ylim([screenDims[1][0]-100,screenDims[1][1]+100])\n",
    "        custom_lines = [Line2D([0], [0], color=c, lw=4) for c in set(colors)]\n",
    "        ax.legend(custom_lines, [colorsRevDict[c] for c in set(colors)])\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "We notice that some users try to follow a linear shape (for example 2|-2416201413375524068), while others are kinda cubic (4). \n",
    "<br> The placement on the screen too, for example the user 8 tries to always stay on the right. \n",
    "<br>  We also notice that some users have tendancy to use the wheel for scrolling (11) while others forget that it even exists such a key (6) and prefer drag instead. \n",
    "<br>  Finally, since clicking usually comes with important screen spots to the user, then we need to use this as a feature too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### Now let's analyse the timeseries behavior too.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:28:30.748026Z",
     "iopub.status.busy": "2023-04-16T13:28:30.747297Z",
     "iopub.status.idle": "2023-04-16T13:30:05.392236Z",
     "shell.execute_reply": "2023-04-16T13:30:05.391014Z",
     "shell.execute_reply.started": "2023-04-16T13:28:30.747984Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# <<-- unscaled timeline || log-log timeline -->>\n",
    "plt.rcParams[\"figure.figsize\"] = [30, 15]\n",
    "for userId in usersEncoder.keys():\n",
    "    portionDf = df[df['user_id']==userId]\n",
    "    print(usersEncoder[userId], userId)\n",
    "    for session in portionDf['session_id'].unique():\n",
    "        portionDfSession = portionDf[portionDf['session_id']==session]\n",
    "        evs = [int(k[1].event_type) for k in portionDfSession.iterrows()] # events\n",
    "        tss = [int(k[1].timestamp) for k in portionDfSession.iterrows()] \n",
    "        # let's plt also the LogLog since, well, some users enjoy taking long breaks..\n",
    "        tss1 = [math.log(math.log(10000+int(k)-tss[0])) for k in tss]\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "        ax1.plot(tss,evs) # base\n",
    "        ax2.plot(tss1,evs) # loglog\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Some users act (click) uniformly (13), while others act only at the middle (12) or beginning/end of the session.\n",
    "<br> Some actions are more concentrated than others. (which means some users perform 'stress' actions like series of fast click, while others are just chilling and only click when it's really necessary).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:30:05.394438Z",
     "iopub.status.busy": "2023-04-16T13:30:05.393827Z",
     "iopub.status.idle": "2023-04-16T13:30:05.404031Z",
     "shell.execute_reply": "2023-04-16T13:30:05.402835Z",
     "shell.execute_reply.started": "2023-04-16T13:30:05.3944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# first we define the schema for the training dataset\n",
    "schemaFeatures = StructType([\n",
    "    StructField('session_id', StringType(), False),\n",
    "    StructField('user_id', StringType(), True),\n",
    "    StructField('user_enc', FloatType(), True),\n",
    "    StructField('center_x', FloatType(), False),\n",
    "    StructField('center_y', FloatType(), False),\n",
    "    StructField('center_click_x', FloatType(), False),\n",
    "    StructField('center_click_y', FloatType(), False),\n",
    "    StructField('first_x', FloatType(), False),\n",
    "    StructField('first_y', FloatType(), False),\n",
    "    StructField('radius', FloatType(), False),\n",
    "    StructField('slope', FloatType(), False),\n",
    "    StructField('narrow', FloatType(), False),\n",
    "    StructField('ev1', FloatType(), False),\n",
    "    StructField('ev2', FloatType(), False),\n",
    "    StructField('ev3', FloatType(), False),\n",
    "    StructField('ev4', FloatType(), False),\n",
    "    StructField('ev5', FloatType(), False),\n",
    "    StructField('stress', IntegerType(), False),\n",
    "    StructField('chill', IntegerType(), False),\n",
    "    StructField('nbpoints', IntegerType(), False),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:30:05.409592Z",
     "iopub.status.busy": "2023-04-16T13:30:05.409207Z",
     "iopub.status.idle": "2023-04-16T13:30:05.433387Z",
     "shell.execute_reply": "2023-04-16T13:30:05.432017Z",
     "shell.execute_reply.started": "2023-04-16T13:30:05.409554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def featurize(recordsIn): \n",
    "    session_id, user_id = recordsIn[0]\n",
    "    records = recordsIn[1]\n",
    "    \n",
    "    center = (lambda axisList: sum(axisList)/len(axisList))\n",
    "    maxRadius = (lambda xc,yc,xList,yList: max([math.sqrt((xi-xc)**2+(yi-yc)**2) for xi, yi in zip(xList,yList)])) \n",
    "    eventRatio = (lambda evKey, allEvents: len([1 for e in allEvents if e==evKey])/len(allEvents))\n",
    "    \n",
    "    # to be more precise, min/max duration of inter-events\n",
    "    minSpeed = (lambda timestamps: min([timestamps[i+1]-timestamps[i] for i in range(len(timestamps)-1)]))\n",
    "    maxSpeed = (lambda timestamps: max([timestamps[i+1]-timestamps[i] for i in range(len(timestamps)-1)]))\n",
    "    \n",
    "    def slope(xList, yList): # the overall curve direction\n",
    "        x_avg = sum(xList)/len(xList)\n",
    "        y_avg = sum(xList)/len(yList)\n",
    "        u=sum([(xi-x_avg)*(yi-y_avg) for xi, yi in zip(xList,yList)])\n",
    "        d=sum([(xi-x_avg)**2 for xi in xList])\n",
    "        return u/d\n",
    "    \n",
    "    def narrow_spark(xList, yList): # we'll use the next function (sklearn) so this one will not be used here sice this part of code will run in a worker. But it can work in a stand alone mode though \n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        data = [(Vectors.dense([xi,yi]),) for xi, yi in zip(xList, yList)]\n",
    "        df = spark.createDataFrame(data,[\"features\"])\n",
    "        pca = spPCA(k=1, inputCol=\"features\")\n",
    "        model = pca.fit(df)\n",
    "        return model.explainedVariance[0]\n",
    "    \n",
    "    def narrow_sklearn(xList, yList): # determine how compact is the curve, like is it line or cube shaped\n",
    "        X = np.array([[xi,yi] for xi, yi in zip(xList, yList)])\n",
    "        pca = skPCA(n_components=1)\n",
    "        pca.fit(X)\n",
    "        return pca.explained_variance_ratio_[0]\n",
    "    \n",
    "    xList = [record['screen_x'] for record in records]\n",
    "    yList = [record['screen_y'] for record in records]\n",
    "    # barycenter of all mouse registered positions\n",
    "    centerX = center(xList)\n",
    "    centerY = center(yList)\n",
    "    \n",
    "    # clicks come with interesting spots. let's use their 'barycenter'\n",
    "    centerClickX = center((lambda x: x if x else [0])([record['screen_x'] for record in records if record['event_type']==5]))\n",
    "    centerClickY = center((lambda x: x if x else [0])([record['screen_y'] for record in records if record['event_type']==5]))\n",
    "    \n",
    "    # The first move is always precious! it reflects the unconscious mind of the user once holds the mouse\n",
    "    firstX = xList[0]\n",
    "    firstY = yList[0]\n",
    "    \n",
    "    # how much space the user takes from the screen (as if we'll put all points inside an imaginary circle)  \n",
    "    tangentCircleRadius = maxRadius(centerX,centerY,xList,yList)\n",
    "    \n",
    "    # curve curvature\n",
    "    slop = slope(xList, yList)\n",
    "    nar = float(narrow_sklearn(xList, yList))\n",
    "\n",
    "    allEvents = [record['event_type'] for record in records]\n",
    "    # frequency of each event\n",
    "    ev1,ev2,ev3,ev4,ev5 = [eventRatio(i, allEvents) for i in range(1,6)]\n",
    "    # how relaxed is the user\n",
    "    stress = minSpeed(sorted([record['timestamp'] for record in records if record['event_type']==2]))\n",
    "    chill = maxSpeed(sorted([record['timestamp'] for record in records if record['event_type']==2])) # maybe we need to apply log here, since some users take long breaks..\n",
    "    # some users use the mouse more often than others\n",
    "    nbpoints = len(xList)\n",
    "    \n",
    "    # TODO: maybe we will need to add more temporal features later, like time center of actions, speed, acceleration, etc.\n",
    "    \n",
    "    if user_id:\n",
    "        userEnc = float(usersEncoder[user_id]) \n",
    "    else:\n",
    "        userEnc = None # will not be used since it's to be predicted\n",
    "    return session_id, user_id, userEnc, centerX, centerY, centerClickX, centerClickY, firstX, firstY, tangentCircleRadius, slop, nar, ev1, ev2, ev3, ev4, ev5, stress, chill, nbpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:30:05.436113Z",
     "iopub.status.busy": "2023-04-16T13:30:05.435329Z",
     "iopub.status.idle": "2023-04-16T13:30:07.316678Z",
     "shell.execute_reply": "2023-04-16T13:30:07.315721Z",
     "shell.execute_reply.started": "2023-04-16T13:30:05.436062Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "featuresDataframe = spark.createDataFrame(\n",
    "    trainDs.rdd.groupBy(lambda x: (x['session_id'], x['user_id'])).map(featurize), schema=schemaFeatures\n",
    ")\n",
    "featuresDataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### Let's have a look at some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:30:07.31902Z",
     "iopub.status.busy": "2023-04-16T13:30:07.317855Z",
     "iopub.status.idle": "2023-04-16T13:30:20.776519Z",
     "shell.execute_reply": "2023-04-16T13:30:20.775287Z",
     "shell.execute_reply.started": "2023-04-16T13:30:07.31898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_featued = featuresDataframe.toPandas()\n",
    "for userId in usersEncoder.keys():\n",
    "    portionDf = df_featued[df_featued['user_id']==userId]\n",
    "    for session in portionDf['session_id'].unique():\n",
    "        portionDfSession = portionDf[portionDf['session_id']==session]\n",
    "        plt.scatter([1,2,3,4,5],portionDfSession[['ev1','ev2','ev3','ev4','ev5']])\n",
    "    print(usersEncoder[userId], userId)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### We can distinguish the user 0 from 17 only by looking at event type ev3!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# TODO: visualize more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:30:20.778162Z",
     "iopub.status.busy": "2023-04-16T13:30:20.777836Z",
     "iopub.status.idle": "2023-04-16T13:30:23.194859Z",
     "shell.execute_reply": "2023-04-16T13:30:23.193641Z",
     "shell.execute_reply.started": "2023-04-16T13:30:20.778129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we compose our features vector column\n",
    "in_col = ['center_x', 'center_y', 'center_click_x', 'center_click_y', 'first_x', 'first_y', 'radius', 'slope', 'narrow', 'ev1', 'ev2', 'ev3', 'ev4', 'ev5', 'stress', 'chill', 'nbpoints']\n",
    "nbusers = featuresDataframe.select('user_enc').distinct().count()\n",
    "assemble = VectorAssembler(inputCols=in_col, outputCol='assembled_features', handleInvalid='error')\n",
    "a_data = assemble.transform(featuresDataframe)\n",
    "scaler = MinMaxScaler(min=0.0, max=1.0, inputCol='assembled_features', outputCol='features')\n",
    "fittedScaler = scaler.fit(a_data)\n",
    "s_data = fittedScaler.transform(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-16T13:30:23.196558Z",
     "iopub.status.busy": "2023-04-16T13:30:23.196121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train-test split. (note that the state 89 is selected because it allows all 20 users on test with such a small 20% share)\n",
    "train_df,test_df = s_data.select('user_enc','features').randomSplit([0.80,0.20],89)\n",
    "print(train_df.select('user_enc').distinct().count())\n",
    "print(test_df.select('user_enc').distinct().count())\n",
    "mlpc=MultilayerPerceptronClassifier( featuresCol='features',labelCol='user_enc',layers = [len(in_col),40,nbusers],maxIter=30000,blockSize=8,seed=7,solver='gd')\n",
    "ann = mlpc.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save the trained model for later\n",
    "ann.save('/kaggle/working/mlp_71_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### PERFORMANCE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='user_enc',predictionCol='prediction',metricName='f1') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def pltConfusion(pred):\n",
    "    array = np.zeros((nbusers,nbusers), int)\n",
    "    for k in pred.collect():\n",
    "        array[int(k['user_enc']),int(k['prediction'])] = array[int(k['user_enc']),int(k['prediction'])]+1\n",
    "    df_cm = pd.DataFrame(array, range(nbusers), range(nbusers))\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sn.set(font_scale=1.4)\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the train performance just for reference\n",
    "pred = ann.transform(train_df)\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print('Train F1 =', ann_f1)\n",
    "pltConfusion(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The more important part:\n",
    "pred = ann.transform(test_df)\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print('Test F1 =', ann_f1)\n",
    "pltConfusion(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "We notice that the model mistakes with the kinda similar patterns, for example it preficts 2 as 16 because they both have linear slim shape. \n",
    "<br> This might be improved by introducing even more features or feeding more train data.\n",
    "<br> It also looks like fell for over-fitting. Let's try to fix it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# We'll apply cross validation, with a grid search to see if it can improve\n",
    "grid = ParamGridBuilder().addGrid(mlpc.layers, [[len(in_col),50,nbusers],[len(in_col),40,30,nbusers]]).build()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='user_enc',predictionCol='prediction',metricName='f1')\n",
    "cv = CrossValidator(estimator=mlpc, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2)\n",
    "cvModel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cvModel.getNumFolds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cvModel.avgMetrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred = cvModel.transform(train_df)\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print('Train F1 =', ann_f1)\n",
    "pltConfusion(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred = cvModel.transform(test_df)\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print('Test F1 =', ann_f1)\n",
    "pltConfusion(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Well, the F1 score of test data didn't improve after applying cross validation.\n",
    "<br> In this case we can test other models like GBT, add more features, and increase the data (either by getting real data or performing some data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cvModel.bestModel.getLayers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cvModel.save('/kaggle/working/cv_70_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### PREDICT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "schemaMousePosTs = StructType([\n",
    "    StructField('uid', StringType(), False,),\n",
    "    StructField('session_id', StringType(), False),\n",
    "    StructField('timestamp', LongType(), False),\n",
    "    StructField('event_type', IntegerType(), False),\n",
    "    StructField('screen_x', FloatType(), False),\n",
    "    StructField('screen_y', FloatType(), False),\n",
    "    StructField('user_id', StringType(), True)\n",
    "])\n",
    "testDs = spark.read.csv('/kaggle/input/mouse-dynamics-for-user-authentication/Test_Mouse.csv',header=True, schema=schemaMousePosTs)\n",
    "testDs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testDs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testDs.select('session_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "ok so we have 40 sessions to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "featuresDataframeTs = spark.createDataFrame(\n",
    "    testDs.rdd.groupBy(lambda x: (x['session_id'], x['user_id'])).map(featurize), schema=schemaFeatures \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "a_data_ts = assemble.transform(featuresDataframeTs)\n",
    "s_data_ts = fittedScaler.transform(a_data_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred = ann.transform(s_data_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred.select(['session_id', 'prediction']).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred.select('session_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred.select('prediction').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "usersDecoder = {v:k for k,v in usersEncoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predPd = pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predPd['user_id'] = predPd['prediction'].apply(lambda x: usersDecoder[int(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predPd[['session_id','user_id']].set_index('session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testDsC = testDs.toPandas().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# now let's save our predictions\n",
    "testDsC.reset_index().set_index('session_id').drop(columns='user_id', inplace=False).\\\n",
    "join(predPd[['session_id','user_id']].set_index('session_id')).\\\n",
    "reset_index()[['index', 'uid', 'session_id', 'user_id', 'timestamp', 'event_type', 'screen_x', 'screen_y']].\\\n",
    "set_index('index').sort_index().to_csv('/kaggle/working/Predicted_mouse.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### During this Machine Learning test case we analysed human input data, trained neural network classification model, and tried to guess the identity of the user behind an unseen behaviour. \n",
    "Although a large gap (25%) between test and training scores has resulted, this gap can pretty well be reduced by trying some of the following techniques:\n",
    "- Try different combination of the neural network model layers.\n",
    "- Try to evaluation other classification models.\n",
    "- Augment the data either by getting more real data or creating some simulations.\n",
    "- Try to compose independent features with high level of separation among the categories (se should think about the human reflex in this case, that guides the mouse, or also the type of bank forms, etc).\n",
    "- It'd be also a good idea to try to approach this problem as a timeseries use case, and train some recurrent models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3139476,
     "sourceId": 5423944,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30458,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "iw2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
